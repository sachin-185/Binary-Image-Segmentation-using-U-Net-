# ğŸ§  Binary Image Segmentation using U-Net 
Developed by **SACHIN S**

---

## ğŸ“Œ Task Overview  
Implement a **U-Net segmentation pipeline** for binary segmentation.  
Includes: data loader, augmentation, Dice-based loss, and CLI support for **train** + **predict** modes.

---

## ğŸ› ï¸ Technology Stack

| Component | Tool / Library |
|-----------|----------------|
| Language | Python 3.8+ |
| Deep Learning | TensorFlow / Keras |
| Data Handling | NumPy, OpenCV, scikit-learn |
| Loss Functions | BCE + Dice |
| Evaluation | Dice Coefficient |
| Input Format | `data/images/*`, `data/masks/*` |
| Output | `unet_vehicle.h5`, `pred_mask.png`, `pred_prob.png` |

## Methodology
### Model Architecture (Why U-Net?)

A U-Net encoderâ€“decoder architecture was selected because:

- Designed specifically for **pixel-level segmentation** tasks.  
- Uses **skip connections** to preserve spatial details lost during downsampling.  
- Performs well even with **limited datasets**, especially when combined with augmentation.  
- Efficient enough to train on mid-range GPUs or even a CPU for small datasets.  
- Provides smooth and accurate object boundaries, unlike plain CNN classifiers.


## ğŸ“‚ Dataset

This project uses a **synthetic binary segmentation dataset** generated programmatically instead of real-world aerial images.

---

## ğŸ§± Architecture Overview:
- `Input: 256Ã—256Ã—3`
- `Encoder:`  
  â–¸ `Conv2D(64) â†’ ReLU â†’ Conv2D(64) â†’ ReLU â†’ MaxPool`  
  â–¸ `Conv2D(128) â†’ ReLU â†’ Conv2D(128) â†’ ReLU â†’ MaxPool`  
  â–¸ `Conv2D(256) â†’ ReLU â†’ Conv2D(256) â†’ ReLU â†’ MaxPool`  
  â–¸ `Conv2D(512) â†’ ReLU â†’ Conv2D(512) â†’ ReLU â†’ MaxPool`  
- `Bottleneck:`  
  â–¸ `Conv2D(1024) â†’ ReLU â†’ Conv2D(1024) â†’ ReLU`  
- `Decoder (Skip Connections):`  
  â–¸ `UpSampling â†’ Concat(c4) â†’ Conv2D(512) Ã—2`  
  â–¸ `UpSampling â†’ Concat(c3) â†’ Conv2D(256) Ã—2`  
  â–¸ `UpSampling â†’ Concat(c2) â†’ Conv2D(128) Ã—2`  
  â–¸ `UpSampling â†’ Concat(c1) â†’ Conv2D(64)  Ã—2`  
- `Output:`  
  â–¸ `Conv2D(1, kernel=1, activation='sigmoid')`  
- **Loss:** `BCE + Dice Loss`  
- **Metric:** `Dice Coefficient`  
- **Optimizer:** `Adam (1e-4)`

âœ… Skip connections  
âœ… Fully convolutional  
âœ… Outputs same resolution mask  

---

## âš™ï¸ Training Config

| Parameter | Value |
|-----------|--------|
| Image Size | 256Ã—256 |
| Batch Size | 2 (default) |
| Epochs | 20 |
| Optimizer | Adam (1e-4) |
| Metric | Dice Coefficient |
| Train/Val Split | 80 / 20 |

---

## ğŸ” How to Run

### 1ï¸âƒ£ Train
```bash
python unet_train.py --data_dir data --epochs 20 --batch 4
```


### 2ï¸âƒ£ Predict on a Single Image
```bash
python unet_train.py --img test.jpg --model unet_vehicle.h5
```

**Output files created:**
- `pred_prob.png` â†’ grayscale probability heatmap
- `pred_mask.png` â†’ binary mask (0/255)

---

## ğŸ“š References
1. Hochreiter, S. & Schmidhuber, J. (1997). *Long Short-Term Memory*. Neural Computation.
2. Chollet, F. (2015). *Keras: Deep Learning library for Theano and TensorFlow*.
3. Brownlee, J. (2017). *Deep Learning for Time Series Forecasting*. Machine Learning Mastery.
4. Srivastava, N. et al. (2014). *Dropout: A Simple Way to Prevent Neural Networks from Overfitting*.
5. TensorFlow Documentation â€“ https://www.tensorflow.org/api_docs
6. Scikit-learn Documentation â€“ https://scikit-learn.org/
7. Time Series Forecasting Best Practices â€“ Microsoft Research



