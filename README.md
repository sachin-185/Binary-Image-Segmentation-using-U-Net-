# ğŸ§  Binary Image Segmentation using U-Net 
Developed by **SACHIN S**

---

## ğŸ“Œ Task Overview  
Implement a **U-Net segmentation pipeline** for binary segmentation.  
Includes: data loader, augmentation, Dice-based loss, and CLI support for **train** + **predict** modes.

---

## ğŸ› ï¸ Technology Stack

| Component | Tool / Library |
|-----------|----------------|
| Language | Python 3.8+ |
| Deep Learning | TensorFlow / Keras |
| Data Handling | NumPy, OpenCV, scikit-learn |
| Loss Functions | BCE + Dice |
| Evaluation | Dice Coefficient |
| Input Format | `data/images/*`, `data/masks/*` |
| Output | `unet_vehicle.h5`, `pred_mask.png`, `pred_prob.png` |

## Methodology
### Model Architecture (Why U-Net?)

A U-Net encoderâ€“decoder architecture was selected because:

- Designed specifically for **pixel-level segmentation** tasks.  
- Uses **skip connections** to preserve spatial details lost during downsampling.  
- Performs well even with **limited datasets**, especially when combined with augmentation.  
- Efficient enough to train on mid-range GPUs or even a CPU for small datasets.  
- Provides smooth and accurate object boundaries, unlike plain CNN classifiers.


## ğŸ“‚ Dataset

This project uses a **synthetic binary segmentation dataset** generated programmatically instead of real-world aerial images.

---

## ğŸ§± Architecture Overview:
- `Input: 256Ã—256Ã—3`
- `Encoder:`  
  â–¸ `Conv2D(64) â†’ ReLU â†’ Conv2D(64) â†’ ReLU â†’ MaxPool`  
  â–¸ `Conv2D(128) â†’ ReLU â†’ Conv2D(128) â†’ ReLU â†’ MaxPool`  
  â–¸ `Conv2D(256) â†’ ReLU â†’ Conv2D(256) â†’ ReLU â†’ MaxPool`  
  â–¸ `Conv2D(512) â†’ ReLU â†’ Conv2D(512) â†’ ReLU â†’ MaxPool`  
- `Bottleneck:`  
  â–¸ `Conv2D(1024) â†’ ReLU â†’ Conv2D(1024) â†’ ReLU`  
- `Decoder (Skip Connections):`  
  â–¸ `UpSampling â†’ Concat(c4) â†’ Conv2D(512) Ã—2`  
  â–¸ `UpSampling â†’ Concat(c3) â†’ Conv2D(256) Ã—2`  
  â–¸ `UpSampling â†’ Concat(c2) â†’ Conv2D(128) Ã—2`  
  â–¸ `UpSampling â†’ Concat(c1) â†’ Conv2D(64)  Ã—2`  
- `Output:`  
  â–¸ `Conv2D(1, kernel=1, activation='sigmoid')`  
- **Loss:** `BCE + Dice Loss`  
- **Metric:** `Dice Coefficient`  
- **Optimizer:** `Adam (1e-4)`

âœ… Skip connections  
âœ… Fully convolutional  
âœ… Outputs same resolution mask  

---

## âš™ï¸ Training Config

| Parameter | Value |
|-----------|--------|
| Image Size | 256Ã—256 |
| Batch Size | 2 (default) |
| Epochs | 20 |
| Optimizer | Adam (1e-4) |
| Metric | Dice Coefficient |
| Train/Val Split | 80 / 20 |

---

### ğŸ“ˆ Training Summary (20 Epochs)

| Metric | Epoch 1 | Epoch 20 |
|--------|---------|----------|
| Training Loss | 1.5437 | 0.5038 |
| Validation Loss | 1.5645 | 0.1832 |
| Dice Coefficient (Train) | 0.1133 | 0.7226 |
| Dice Coefficient (Val) | 0.0486 | 0.8344 |

âœ… Best model saved as: `unet_vehicle.h5`  

---

### ğŸ” Raw Log (Condensed)

Epoch 1/20  - loss: 1.5437 - dice: 0.1133 - val_dice: 0.0486  
Epoch 10/20 - loss: 1.0492 - dice: 0.1487 - val_dice: 0.1297  
Epoch 15/20 - loss: 0.7974 - dice: 0.3760 - val_dice: 0.4309  
Epoch 20/20 - loss: 0.5038 - dice: 0.7226 - val_dice: 0.8344  

âœ… Training complete   

--

## âœ… Pros of U-Net
- Works extremely well with limited training data (data-efficient).
- Skip connections help preserve spatial details â†’ sharper masks.
- Symmetric encoder-decoder design enables multi-scale feature learning.
- Lightweight and trainable on mid-range GPUs/CPUs.
- Widely used and benchmark-proven in biomedical, satellite, and vehicle segmentation.
- Easy to modify (attention U-Net, ResU-Net, U-Net++, etc.).

## âŒ Cons of U-Net**
- Struggles with very large high-resolution images due to memory usage.
- No explicit handling of temporal or 3D context (not ideal for video or volumetric data unless extended).
- May overfit if the dataset is too synthetic or lacks real-world variance.
- Performance drops on extremely small or thin objects (boundaries may blur).
- Vanilla U-Net does not model long-range dependencies (no self-attention like Transformers).

--

## ğŸ” How to Run

### 1ï¸âƒ£ Train
```bash
python unet_train.py --data_dir data --epochs 20 --batch 4
```


### 2ï¸âƒ£ Predict on a Single Image
```bash
python unet_train.py --img test.jpg --model unet_vehicle.h5
```

**Output files created:**
- `pred_prob.png` â†’ grayscale probability heatmap
- `pred_mask.png` â†’ binary mask (0/255)

---

## ğŸ“š References
1. Hochreiter, S. & Schmidhuber, J. (1997). *Long Short-Term Memory*. Neural Computation.
2. Chollet, F. (2015). *Keras: Deep Learning library for Theano and TensorFlow*.
3. Brownlee, J. (2017). *Deep Learning for Time Series Forecasting*. Machine Learning Mastery.
4. Srivastava, N. et al. (2014). *Dropout: A Simple Way to Prevent Neural Networks from Overfitting*.
5. TensorFlow Documentation â€“ https://www.tensorflow.org/api_docs
6. Scikit-learn Documentation â€“ https://scikit-learn.org/
7. Time Series Forecasting Best Practices â€“ Microsoft Research



